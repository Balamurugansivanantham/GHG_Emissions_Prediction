{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Greenhouse Gas Emissions Prediction from Supply Chain Data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# Load Data Function\n",
    "# -------------------------------\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(\"Data loaded successfully.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "        return None\n",
    "\n",
    "# -------------------------------\n",
    "# Preprocess Data Function\n",
    "# -------------------------------\n",
    "def preprocess_data(df):\n",
    "    print(\"Initial shape:\", df.shape)\n",
    "\n",
    "    # Drop rows with any missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Convert categorical variables if necessary\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "    print(\"Processed shape:\", df.shape)\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# Train and Evaluate Model\n",
    "# -------------------------------\n",
    "def train_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', RandomForestRegressor(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'regressor__n_estimators': [100, 200],\n",
    "        'regressor__max_depth': [None, 10, 20]\n",
    "    }\n",
    "\n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"RÂ² Score:\", r2_score(y_test, y_pred))\n",
    "    print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(grid_search.best_estimator_, \"ghg_emission_model.pkl\")\n",
    "\n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "    plt.xlabel(\"Actual Emissions\")\n",
    "    plt.ylabel(\"Predicted Emissions\")\n",
    "    plt.title(\"Actual vs Predicted Emissions\")\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Feature importances\n",
    "    model = grid_search.best_estimator_.named_steps['regressor']\n",
    "    importances = model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(importances)), importances[sorted_idx], align='center')\n",
    "    plt.yticks(range(len(importances)), np.array(feature_names)[sorted_idx])\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.title(\"Feature Importances from Random Forest\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# Main Execution\n",
    "# -------------------------------\n",
    "file_path = 'SupplyChainEmissionFactorsforUSIndustriesCommodities.xlsx'\n",
    "df = load_data(file_path)\n",
    "\n",
    "if df is not None:\n",
    "    df = preprocess_data(df)\n",
    "\n",
    "    # Assuming the target variable is named like this (adjust if different)\n",
    "    target_col = 'Supply Chain Emission Factor with Margin'\n",
    "\n",
    "    if target_col in df.columns:\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "        train_model(X, y)\n",
    "    else:\n",
    "        print(f\"Target column '{target_col}' not found in dataset.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
