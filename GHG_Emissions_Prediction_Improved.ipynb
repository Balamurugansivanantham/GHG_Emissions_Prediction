{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a7875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GHG Emissions Prediction using Random Forest\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set path to Excel file\n",
    "excel_file = 'SupplyChainEmissionFactorsforUSIndustriesCommodities.xlsx'  # Make sure to place this file correctly\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(excel_file):\n",
    "    raise FileNotFoundError(f\"The file '{excel_file}' was not found. Please check the path or upload the file.\")\n",
    "\n",
    "# Load data across multiple years\n",
    "years = range(2010, 2017)\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    try:\n",
    "        df = pd.read_excel(excel_file, sheet_name=f'{year}_Detail_Commodity')\n",
    "        df['Year'] = year\n",
    "        all_data.append(df)\n",
    "        logging.info(f\"Loaded data for year {year}\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error processing year {year}: {e}\")\n",
    "\n",
    "# Concatenate all data\n",
    "if not all_data:\n",
    "    raise ValueError(\"No data was loaded. Please check the Excel sheets.\")\n",
    "\n",
    "df = pd.concat(all_data, ignore_index=True)\n",
    "logging.info(\"All yearly data loaded and concatenated.\")\n",
    "\n",
    "# Drop unnecessary columns and handle missing values\n",
    "df.dropna(inplace=True)\n",
    "df = df.select_dtypes(include=[np.number])  # Keep only numeric columns\n",
    "\n",
    "# Basic correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=False, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Define features and target (example target: 'Total Emissions'; replace as appropriate)\n",
    "target_column = 'Total Emissions'  # Change this to the actual target column name in your dataset\n",
    "\n",
    "if target_column not in df.columns:\n",
    "    raise ValueError(f\"'{target_column}' column not found in the dataset.\")\n",
    "\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model training with Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"R-squared (RÂ²):\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"Model and scaler saved.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}